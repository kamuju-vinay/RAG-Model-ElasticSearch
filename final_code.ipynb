{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03e5f86-3939-48e7-b59b-f5f9910d933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_cohere import ChatCohere, CohereEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b8f0f5-dbf8-422d-8ee6-fce8e95b6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to load HTML content from a URL\n",
    "def load_html_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Initialize Cohere embeddings model\n",
    "embeddings_model = CohereEmbeddings(\n",
    "    model=\"embed-english-light-v2.0\", cohere_api_key=\"ERQgasyWTOr2fPq4NQOyHkPxAFM90cgH1oOknZft\"\n",
    ")\n",
    "\n",
    "# Load documents from URLs\n",
    "urls = [\"https://americanliterature.com/author/o-henry/short-story/a-newspaper-story/\"]\n",
    "docs = [Document(page_content=load_html_content(url), metadata={\"source\": url}) for url in urls]\n",
    "\n",
    "# Transform HTML documents to text (if necessary)\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "\n",
    "# Split documents into smaller chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = splitter.split_documents(docs_transformed)\n",
    "\n",
    "# Generate embeddings for the document chunks\n",
    "split_texts = [doc.page_content for doc in splits]\n",
    "doc_embeddings = embeddings_model.embed_documents(split_texts)\n",
    "\n",
    "# Initialize the Elasticsearch store with the embeddings and document chunks\n",
    "vector_db = ElasticsearchStore.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings_model,\n",
    "    index_name='webscraping',\n",
    "    es_cloud_id=\"webscraping:dXMtZWFzdC0yLmF3cy5lbGFzdGljLWNsb3VkLmNvbTo0NDMkMWJhODg3YmQ5ZDkwNDAzZDgwZTI1ODkyOTA2YzFjYmYkZWZkMTk2MjE3NjQ3NDBkZWI5NTY1NjlkODY0NTMzZWM=\",\n",
    "    es_api_key=\"bkVWYlRwQUJaX3ZvdDItTVk2dWE6VE8zc2RzdXpTbk9MZzdDeGdxUlRBdw==\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefed592-86d2-4573-8848-e490637f07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for the retriving of the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013eb0ea-5a8a-4083-96d8-5efc617255b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = ElasticsearchStore(\n",
    "    embedding=embeddings_model,\n",
    "    index_name='webscraping',\n",
    "    es_cloud_id=\"webscraping:dXMtZWFzdC0yLmF3cy5lbGFzdGljLWNsb3VkLmNvbTo0NDMkMWJhODg3YmQ5ZDkwNDAzZDgwZTI1ODkyOTA2YzFjYmYkZWZkMTk2MjE3NjQ3NDBkZWI5NTY1NjlkODY0NTMzZWM=\",\n",
    "    es_api_key=\"bkVWYlRwQUJaX3ZvdDItTVk2dWE6VE8zc2RzdXpTbk9MZzdDeGdxUlRBdw==\"\n",
    ")\n",
    "# Create a retriever from the Elasticsearch store\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "# Define the prompt template\n",
    "template = '''Answer the question based on the following context.\n",
    "If the answer does not contain any relevant information to the user query, do not make something up and just say \"I don't know!\" without any description.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Human Question :: {input}\n",
    "'''\n",
    "\n",
    "# Initialize the ChatPromptTemplate with the template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the ChatCohere instance with the Cohere API key\n",
    "llm = ChatCohere(cohere_api_key=\"ERQgasyWTOr2fPq4NQOyHkPxAFM90cgH1oOknZft\")\n",
    "\n",
    "# Define the output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Define the pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f291896a-634b-4da2-b349-0d242b867a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a proud elephant who enjoyed bullying smaller animals. He would go to the anthill near his home and spray water at the ants, knowing they couldn't do anything because of their size. The elephant would laugh and threaten to crush the ants. However, the ants decided to teach the elephant a lesson. They crawled into the elephant's trunk and bit him, causing the elephant to howl in pain. Realizing his mistake, the elephant apologized to the ants and all the animals he had bullied. The moral of the story is to be humble and treat everyone with kindness, regardless of their size or strength.\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = \"tell me a story of ant\"\n",
    "\n",
    "# Invoke the pipeline with the query\n",
    "response = chain.invoke(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031adee9-6d04-4c1d-8262-18f50c3490d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short story about a newspaper:\n",
      "\n",
      "Once upon a time, there was a young boy named Johnny who attended a private school. He often got into trouble with his teacher and frequently faced corporal punishment. One day, Johnny came up with a clever plan to protect himself. He took the newspaper, which featured an editorial against corporal punishment, and carefully cut out columns. He then hid these columns inside his clothes, placing them over areas commonly targeted during beatings. The ink from the newspaper, with its colorful and bold headlines, successfully defended Johnny from any attacks on those areas. \n",
      "\n",
      "The power of the press was truly demonstrated that day, as the newspaper's words not only influenced public opinion but also quite literally shielded Johnny from harm. This story showcases how something as simple as a newspaper can have a significant impact and even become a tool for protection and change.\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = \"tell me a story of news paper \"\n",
    "\n",
    "# Invoke the pipeline with the query\n",
    "response = chain.invoke(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639e6be1-91b7-42c1-9447-e7d10471222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The moral of the story is \"Be humble and treat everyone with kindness. If you think you’re stronger than others, use your strength to protect them instead of harming them.\" The elephant and the ants do not have names in this story.\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = \"what is the moral of elphant and ant story and there names\"\n",
    "\n",
    "# Invoke the pipeline with the query\n",
    "response = chain.invoke(query)\n",
    "\n",
    "# Print the response\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8811cc3e-299a-47cb-adfd-3a8d0d13a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An anthill is a mound of earth and debris built by ants as their home. In the story \"The Elephant and the Ants,\" the elephant would go to the anthill near his home and spray water at the ants, bullying them due to their smaller size.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the query\n",
    "query = \"what is anthill in elephant and story ?\"\n",
    "\n",
    "# Invoke the pipeline with the query\n",
    "response = chain.invoke(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cbd8032-a49c-4108-a288-40d8d5b7e8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheep and wolves.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the query\n",
    "query = \"what are the all animals are there in all storyes?\"\n",
    "\n",
    "# Invoke the pipeline with the query\n",
    "response = chain.invoke(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d8ff229-e62b-47fa-9c0a-af4113a7fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a short story about a boy who cried wolf. \n",
      "\n",
      "**The Boy Who Cried Wolf**\n",
      "\n",
      "There was once a shepherd boy who liked to play tricks. One day, while watching over the herd, he cried out “Wolf! Wolf!”, causing people to rush to his aid, only to find that there was no wolf and the boy had played a trick on them. The boy repeated this prank the next day, with the same result. On the third day, the boy actually saw a wolf devouring one of his sheep, and cried for help. However, those who heard him assumed it was another prank, and so no one came to help. The boy lost some of his sheep to the wolf. \n",
      "\n",
      "**Moral of the Story:**\n",
      "\n",
      "If you always lie and cheat on other people, there will come a time when no one will believe you anymore.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the query\n",
    "query = \"tell me all small story on wolf and moral\"\n",
    "\n",
    "# Invoke the pipeline with the query\n",
    "response = chain.invoke(query)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23c81e7-e7f6-4b13-be2e-89480e91ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add loggins and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc7f4b98-d460-4483-b1ff-8b38cde9d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_cohere import ChatCohere, CohereEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8810d144-3abb-44ed-88e0-81e0648c50ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initialized Cohere embeddings model\n",
      "INFO:__main__:Loaded content from URL: https://americanliterature.com/author/o-henry/short-story/a-newspaper-story/\n",
      "INFO:__main__:Loaded documents from URLs\n",
      "INFO:__main__:Transformed HTML documents to text\n",
      "INFO:__main__:Split documents into smaller chunks\n",
      "INFO:__main__:Generated embeddings for the document chunks\n",
      "INFO:elastic_transport.transport:GET https://1ba887bd9d90403d80e25892906c1cbf.us-east-2.aws.elastic-cloud.com:443/ [status:200 duration:1.200s]\n",
      "INFO:elastic_transport.transport:HEAD https://1ba887bd9d90403d80e25892906c1cbf.us-east-2.aws.elastic-cloud.com:443/webscraping [status:200 duration:0.284s]\n",
      "INFO:elastic_transport.transport:PUT https://1ba887bd9d90403d80e25892906c1cbf.us-east-2.aws.elastic-cloud.com:443/_bulk?refresh=true [status:200 duration:0.625s]\n",
      "INFO:__main__:Initialized Elasticsearch store with the embeddings and document chunks\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to load HTML content from a URL\n",
    "def load_html_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        logger.info(f\"Loaded content from URL: {url}\")\n",
    "        return soup.get_text()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error loading URL {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Initialize Cohere embeddings model\n",
    "embeddings_model = CohereEmbeddings(\n",
    "    model=\"embed-english-light-v2.0\", cohere_api_key=\"ERQgasyWTOr2fPq4NQOyHkPxAFM90cgH1oOknZft\"\n",
    ")\n",
    "logger.info(\"Initialized Cohere embeddings model\")\n",
    "\n",
    "# Load documents from URLs\n",
    "urls = [\"https://americanliterature.com/author/o-henry/short-story/a-newspaper-story/\"]\n",
    "docs = [Document(page_content=load_html_content(url), metadata={\"source\": url}) for url in urls]\n",
    "logger.info(\"Loaded documents from URLs\")\n",
    "\n",
    "# Transform HTML documents to text (if necessary)\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "logger.info(\"Transformed HTML documents to text\")\n",
    "\n",
    "# Split documents into smaller chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = splitter.split_documents(docs_transformed)\n",
    "logger.info(\"Split documents into smaller chunks\")\n",
    "\n",
    "# Generate embeddings for the document chunks\n",
    "split_texts = [doc.page_content for doc in splits]\n",
    "doc_embeddings = embeddings_model.embed_documents(split_texts)\n",
    "logger.info(\"Generated embeddings for the document chunks\")\n",
    "\n",
    "# Initialize the Elasticsearch store with the embeddings and document chunks\n",
    "vector_db = ElasticsearchStore.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings_model,\n",
    "    index_name='webscraping',\n",
    "    es_cloud_id=\"webscraping:dXMtZWFzdC0yLmF3cy5lbGFzdGljLWNsb3VkLmNvbTo0NDMkMWJhODg3YmQ5ZDkwNDAzZDgwZTI1ODkyOTA2YzFjYmYkZWZkMTk2MjE3NjQ3NDBkZWI5NTY1NjlkODY0NTMzZWM=\",\n",
    "    es_api_key=\"bkVWYlRwQUJaX3ZvdDItTVk2dWE6VE8zc2RzdXpTbk9MZzdDeGdxUlRBdw==\"\n",
    ")\n",
    "logger.info(\"Initialized Elasticsearch store with the embeddings and document chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0955cc-9b70-4a49-b06b-ce640aa9d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a retriever from the Elasticsearch store\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "# Advanced Query Handling\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_query(query):\n",
    "    words = query.split()\n",
    "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Define the prompt template\n",
    "template = '''Answer the question based on the following context.\n",
    "If the answer does not contain any relevant information to the user query, do not make something up and just say \"I don't know!\" without any description.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Human Question :: {input}\n",
    "'''\n",
    "\n",
    "# Initialize the ChatPromptTemplate with the template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the ChatCohere instance with the Cohere API key\n",
    "llm = ChatCohere(cohere_api_key=\"ERQgasyWTOr2fPq4NQOyHkPxAFM90cgH1oOknZft\")\n",
    "\n",
    "# Define the output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Define the pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e0df24-eaf3-4052-a8a1-1427037493b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessed query: give summari newspap stori\n",
      "INFO:elastic_transport.transport:POST https://1ba887bd9d90403d80e25892906c1cbf.us-east-2.aws.elastic-cloud.com:443/webscraping/_search?_source_includes=metadata,text [status:200 duration:0.301s]\n",
      "INFO:httpx:HTTP Request: GET https://api.cohere.com/v1/models?default_only=true&endpoint=chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Response: A young man driving a buggy is startled by a newspaper that blows against his horse's face. The horse bolts and the buggy crashes, leaving the man injured on the street. He is carried into a nearby brownstone mansion, where a woman tends to him, revealing that she is the one he has been pursuing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A young man driving a buggy is startled by a newspaper that blows against his horse's face. The horse bolts and the buggy crashes, leaving the man injured on the street. He is carried into a nearby brownstone mansion, where a woman tends to him, revealing that she is the one he has been pursuing.\n"
     ]
    }
   ],
   "source": [
    "# Define the query and preprocess it\n",
    "query = \"Give me the summary of the newspaper story\"\n",
    "preprocessed_query = preprocess_query(query)\n",
    "logger.info(f\"Preprocessed query: {preprocessed_query}\")\n",
    "\n",
    "# Invoke the pipeline with the preprocessed query\n",
    "response = chain.invoke(preprocessed_query)\n",
    "\n",
    "# Print the response\n",
    "print(response)\n",
    "logger.info(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5494603-899b-4943-a2bf-39881f45665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
